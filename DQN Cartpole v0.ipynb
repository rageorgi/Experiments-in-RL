{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "659ec131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26a64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "# def randomgames():\n",
    "    \n",
    "#     for i in range(1):\n",
    "#         state = env.reset()\n",
    "        \n",
    "#         for t in range(500):\n",
    "            \n",
    "#             env.render()\n",
    "#             action = env.action_space.sample()\n",
    "            \n",
    "#             new_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            \n",
    "#             print(t, new_state, reward, done, info)\n",
    "            \n",
    "#             if done:\n",
    "#                 break\n",
    "#     env.close()\n",
    "                \n",
    "# randomgames()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b83ff628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNmodel(input_shape, action_space):\n",
    "    \n",
    "    X_input = layers.Input(input_shape)\n",
    "    X = layers.Dense(512, input_shape = input_shape, activation = \"relu\", kernel_initializer = 'he_uniform')(X_input)\n",
    "    X = layers.Dense(256, activation = \"relu\", kernel_initializer = 'he_uniform')(X)\n",
    "    X = layers.Dense(64, activation = \"relu\", kernel_initializer = 'he_uniform')(X)\n",
    "    X_output = layers.Dense(action_space, activation = \"linear\", kernel_initializer = 'he_uniform')(X)\n",
    "    \n",
    "    model = models.Model(inputs = X_input, outputs = X_output, name='CartPole_DQN_model')   #Change\n",
    "    \n",
    "    model.compile(loss = \"mse\", optimizer = RMSprop(lr = 0.00025, rho = 0.95, epsilon = 0.01), metrics = [\"accuracy\"])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "810349ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.env = gym.make('CartPole-v0')\n",
    "        # by default, CartPole-v1 has max episode steps = 200\n",
    "        self.state_size = self.env.observation_space.shape[0]\n",
    "        self.action_size = self.env.action_space.n\n",
    "        self.EPISODES = 1000\n",
    "        self.testEPISODES = 100\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        \n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.001\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 1000\n",
    "        \n",
    "        # For stats\n",
    "        self.ep_rewards = []\n",
    "        self.aggr_ep_rewards = {'ep': [], 'avg': [], 'max': [], 'min': []}\n",
    "        self.STATS_EVERY = 25\n",
    "\n",
    "        \n",
    "\n",
    "        # create main model\n",
    "        #self.model = NNmodel(input_shape = self.state_size, action_space = self.action_size)    #Why doesn't this work?\n",
    "        self.model = NNmodel(input_shape=(self.state_size,), action_space = self.action_size)\n",
    "        \n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if len(self.memory) > self.train_start:                \n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            return np.argmax(self.model.predict(state))\n",
    "        \n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        # Randomly sample minibatch from the memory\n",
    "        minibatch = random.sample(self.memory, min(len(self.memory), self.batch_size))\n",
    "\n",
    "        state = np.zeros((self.batch_size, self.state_size))\n",
    "        next_state = np.zeros((self.batch_size, self.state_size))\n",
    "        action, reward, done = [], [], []\n",
    "\n",
    "        # do this before prediction\n",
    "        # for speedup, this could be done on the tensor level\n",
    "        # but easier to understand using a loop\n",
    "        for i in range(self.batch_size):\n",
    "            state[i] = minibatch[i][0]\n",
    "            action.append(minibatch[i][1])\n",
    "            reward.append(minibatch[i][2])\n",
    "            next_state[i] = minibatch[i][3]\n",
    "            done.append(minibatch[i][4])\n",
    "\n",
    "        # do batch prediction to save speed\n",
    "        target = self.model.predict(state)\n",
    "        target_next = self.model.predict(next_state)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            # correction on the Q value for the action used\n",
    "            if done[i]:\n",
    "                target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                # Standard - DQN\n",
    "                # DQN chooses the max Q value among next actions\n",
    "                # selection and evaluation of action is on the target Q Network\n",
    "                # Q_max = max_a' Q_target(s', a')\n",
    "                target[i][action[i]] = reward[i] + self.gamma * (np.amax(target_next[i]))\n",
    "\n",
    "        # Train the Neural Network with batches\n",
    "        self.model.fit(state, target, batch_size=self.batch_size, verbose=0)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    def load(self, name):\n",
    "        self.model = models.load_model(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)\n",
    "            \n",
    "    def run(self):        \n",
    "        for e in range(self.EPISODES):\n",
    "            state = self.env.reset()\n",
    "            state = np.reshape(state, [1, self.state_size])\n",
    "            done = False\n",
    "            i = 0\n",
    "            \n",
    "            episode_reward = 0\n",
    "            \n",
    "            while not done:\n",
    "                #self.env.render()\n",
    "                action = self.act(state)\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                next_state = np.reshape(next_state, [1, self.state_size])\n",
    "                \n",
    "                episode_reward += reward     #Without penalty for failure\n",
    "                \n",
    "                #if not done or i == self.env._max_episode_steps-1:     #Hmmm messing with the environment rewards is allowed?\n",
    "                #    reward = reward\n",
    "                #else:\n",
    "                #    reward = -100\n",
    "                    \n",
    "                #episode_reward += reward    #With penalty for failure\n",
    "                    \n",
    "                self.remember(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                i += 1\n",
    "                if done:                   \n",
    "                    print(\"episode: {}/{}, score: {}, e: {:.2}\".format(e, self.EPISODES, i, self.epsilon))\n",
    "                    if i == 200 and e >= 125:\n",
    "                        print(\"Saving trained model as cartpole-dqn.h5\")\n",
    "                        self.save(\"cartpolev0-dqn.h5\")\n",
    "                        return\n",
    "                self.replay()\n",
    "                \n",
    "                \n",
    "            self.ep_rewards.append(episode_reward)\n",
    "            \n",
    "            if not e % self.STATS_EVERY:\n",
    "                average_reward = sum(self.ep_rewards[-self.STATS_EVERY:])/self.STATS_EVERY\n",
    "                self.aggr_ep_rewards['ep'].append(e)\n",
    "                self.aggr_ep_rewards['avg'].append(average_reward)\n",
    "                self.aggr_ep_rewards['max'].append(max(self.ep_rewards[-self.STATS_EVERY:]))\n",
    "                self.aggr_ep_rewards['min'].append(min(self.ep_rewards[-self.STATS_EVERY:]))\n",
    "                print(f'Episode: {e:>5d}, average reward: {average_reward:>4.1f}, current epsilon: {self.epsilon:>1.2f}')  \n",
    "                \n",
    "  \n",
    "    def test(self):\n",
    "        self.load(\"cartpolev0-dqn.h5\")\n",
    "        for e in range(self.testEPISODES):\n",
    "            state = self.env.reset()\n",
    "            state = np.reshape(state, [1, self.state_size])\n",
    "            done = False\n",
    "            i = 0\n",
    "            while not done:\n",
    "                #self.env.render()\n",
    "                action = np.argmax(self.model.predict(state))\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                state = np.reshape(next_state, [1, self.state_size])\n",
    "                i += 1\n",
    "                if done:\n",
    "                    print(\"episode: {}/{}, score: {}\".format(e+1, self.testEPISODES, i))\n",
    "                    break\n",
    "                    \n",
    "    def performance(self):\n",
    "        plt.plot(self.aggr_ep_rewards['ep'], self.aggr_ep_rewards['avg'], label=\"average rewards\")\n",
    "        plt.plot(self.aggr_ep_rewards['ep'], self.aggr_ep_rewards['max'], label=\"max rewards\")\n",
    "        plt.plot(self.aggr_ep_rewards['ep'], self.aggr_ep_rewards['min'], label=\"min rewards\")\n",
    "        plt.legend(loc=4)\n",
    "        plt.title(\"Training Log (Interval size: 25)\")\n",
    "        plt.xlabel(\"Episodes\")\n",
    "        plt.ylabel(\"Reward\")\n",
    "        plt.savefig('plot.png', dpi=300)\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446e983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CartPole_DQN_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2560      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 150,466\n",
      "Trainable params: 150,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0/1000, score: 23, e: 1.0\n",
      "Episode:     0, average reward:  0.9, current epsilon: 1.00\n",
      "episode: 1/1000, score: 13, e: 1.0\n",
      "episode: 2/1000, score: 31, e: 1.0\n",
      "episode: 3/1000, score: 48, e: 1.0\n",
      "episode: 4/1000, score: 11, e: 1.0\n",
      "episode: 5/1000, score: 48, e: 1.0\n",
      "episode: 6/1000, score: 24, e: 1.0\n",
      "episode: 7/1000, score: 28, e: 1.0\n",
      "episode: 8/1000, score: 14, e: 1.0\n",
      "episode: 9/1000, score: 38, e: 1.0\n",
      "episode: 10/1000, score: 13, e: 1.0\n",
      "episode: 11/1000, score: 27, e: 1.0\n",
      "episode: 12/1000, score: 25, e: 1.0\n",
      "episode: 13/1000, score: 16, e: 1.0\n",
      "episode: 14/1000, score: 13, e: 1.0\n",
      "episode: 15/1000, score: 16, e: 1.0\n",
      "episode: 16/1000, score: 52, e: 1.0\n",
      "episode: 17/1000, score: 16, e: 1.0\n",
      "episode: 18/1000, score: 26, e: 1.0\n",
      "episode: 19/1000, score: 26, e: 1.0\n",
      "episode: 20/1000, score: 23, e: 1.0\n",
      "episode: 21/1000, score: 26, e: 1.0\n",
      "episode: 22/1000, score: 41, e: 1.0\n",
      "episode: 23/1000, score: 20, e: 1.0\n",
      "episode: 24/1000, score: 20, e: 1.0\n",
      "episode: 25/1000, score: 16, e: 1.0\n",
      "Episode:    25, average reward: 25.2, current epsilon: 1.00\n",
      "episode: 26/1000, score: 16, e: 1.0\n",
      "episode: 27/1000, score: 20, e: 1.0\n",
      "episode: 28/1000, score: 39, e: 1.0\n",
      "episode: 29/1000, score: 20, e: 1.0\n",
      "episode: 30/1000, score: 25, e: 1.0\n",
      "episode: 31/1000, score: 17, e: 1.0\n",
      "episode: 32/1000, score: 10, e: 1.0\n",
      "episode: 33/1000, score: 39, e: 1.0\n",
      "episode: 34/1000, score: 19, e: 1.0\n",
      "episode: 35/1000, score: 22, e: 1.0\n",
      "episode: 36/1000, score: 14, e: 1.0\n",
      "episode: 37/1000, score: 39, e: 1.0\n",
      "episode: 38/1000, score: 28, e: 1.0\n",
      "episode: 39/1000, score: 32, e: 1.0\n",
      "episode: 40/1000, score: 19, e: 0.99\n",
      "episode: 41/1000, score: 12, e: 0.98\n",
      "episode: 42/1000, score: 18, e: 0.96\n",
      "episode: 43/1000, score: 19, e: 0.94\n",
      "episode: 44/1000, score: 10, e: 0.93\n",
      "episode: 45/1000, score: 20, e: 0.91\n",
      "episode: 46/1000, score: 11, e: 0.9\n",
      "episode: 47/1000, score: 28, e: 0.88\n",
      "episode: 48/1000, score: 20, e: 0.86\n",
      "episode: 49/1000, score: 11, e: 0.85\n",
      "episode: 50/1000, score: 17, e: 0.84\n",
      "Episode:    50, average reward: 21.0, current epsilon: 0.84\n",
      "episode: 51/1000, score: 16, e: 0.82\n",
      "episode: 52/1000, score: 15, e: 0.81\n",
      "episode: 53/1000, score: 39, e: 0.78\n",
      "episode: 54/1000, score: 17, e: 0.77\n",
      "episode: 55/1000, score: 13, e: 0.76\n",
      "episode: 56/1000, score: 14, e: 0.75\n",
      "episode: 57/1000, score: 24, e: 0.73\n",
      "episode: 58/1000, score: 21, e: 0.71\n",
      "episode: 59/1000, score: 11, e: 0.71\n",
      "episode: 60/1000, score: 10, e: 0.7\n",
      "episode: 61/1000, score: 14, e: 0.69\n",
      "episode: 62/1000, score: 19, e: 0.68\n",
      "episode: 63/1000, score: 18, e: 0.66\n",
      "episode: 64/1000, score: 21, e: 0.65\n",
      "episode: 65/1000, score: 9, e: 0.64\n",
      "episode: 66/1000, score: 12, e: 0.64\n",
      "episode: 67/1000, score: 13, e: 0.63\n",
      "episode: 68/1000, score: 11, e: 0.62\n",
      "episode: 69/1000, score: 11, e: 0.61\n",
      "episode: 70/1000, score: 11, e: 0.61\n",
      "episode: 71/1000, score: 10, e: 0.6\n",
      "episode: 72/1000, score: 13, e: 0.59\n",
      "episode: 73/1000, score: 18, e: 0.58\n",
      "episode: 74/1000, score: 14, e: 0.58\n",
      "episode: 75/1000, score: 9, e: 0.57\n",
      "Episode:    75, average reward: 15.3, current epsilon: 0.57\n",
      "episode: 76/1000, score: 14, e: 0.56\n",
      "episode: 77/1000, score: 10, e: 0.56\n",
      "episode: 78/1000, score: 13, e: 0.55\n",
      "episode: 79/1000, score: 11, e: 0.54\n",
      "episode: 80/1000, score: 12, e: 0.54\n",
      "episode: 81/1000, score: 25, e: 0.52\n",
      "episode: 82/1000, score: 11, e: 0.52\n",
      "episode: 83/1000, score: 13, e: 0.51\n",
      "episode: 84/1000, score: 9, e: 0.51\n",
      "episode: 85/1000, score: 10, e: 0.5\n",
      "episode: 86/1000, score: 13, e: 0.49\n",
      "episode: 87/1000, score: 11, e: 0.49\n",
      "episode: 88/1000, score: 17, e: 0.48\n",
      "episode: 89/1000, score: 18, e: 0.47\n",
      "episode: 90/1000, score: 12, e: 0.47\n",
      "episode: 91/1000, score: 15, e: 0.46\n",
      "episode: 92/1000, score: 12, e: 0.45\n",
      "episode: 93/1000, score: 14, e: 0.45\n",
      "episode: 94/1000, score: 9, e: 0.44\n",
      "episode: 95/1000, score: 11, e: 0.44\n",
      "episode: 96/1000, score: 10, e: 0.43\n",
      "episode: 97/1000, score: 9, e: 0.43\n",
      "episode: 98/1000, score: 12, e: 0.43\n",
      "episode: 99/1000, score: 17, e: 0.42\n",
      "episode: 100/1000, score: 10, e: 0.41\n",
      "Episode:   100, average reward: 12.7, current epsilon: 0.41\n",
      "episode: 101/1000, score: 12, e: 0.41\n",
      "episode: 102/1000, score: 13, e: 0.4\n",
      "episode: 103/1000, score: 12, e: 0.4\n",
      "episode: 104/1000, score: 14, e: 0.39\n",
      "episode: 105/1000, score: 16, e: 0.39\n",
      "episode: 106/1000, score: 12, e: 0.38\n",
      "episode: 107/1000, score: 10, e: 0.38\n",
      "episode: 108/1000, score: 11, e: 0.38\n",
      "episode: 109/1000, score: 11, e: 0.37\n",
      "episode: 110/1000, score: 11, e: 0.37\n",
      "episode: 111/1000, score: 13, e: 0.36\n",
      "episode: 112/1000, score: 10, e: 0.36\n",
      "episode: 113/1000, score: 10, e: 0.36\n",
      "episode: 114/1000, score: 9, e: 0.35\n",
      "episode: 115/1000, score: 8, e: 0.35\n",
      "episode: 116/1000, score: 11, e: 0.35\n",
      "episode: 117/1000, score: 8, e: 0.34\n",
      "episode: 118/1000, score: 11, e: 0.34\n",
      "episode: 119/1000, score: 12, e: 0.33\n",
      "episode: 120/1000, score: 10, e: 0.33\n",
      "episode: 121/1000, score: 10, e: 0.33\n",
      "episode: 122/1000, score: 11, e: 0.32\n",
      "episode: 123/1000, score: 14, e: 0.32\n",
      "episode: 124/1000, score: 11, e: 0.32\n",
      "episode: 125/1000, score: 12, e: 0.31\n",
      "Episode:   125, average reward: 11.3, current epsilon: 0.31\n",
      "episode: 126/1000, score: 10, e: 0.31\n",
      "episode: 127/1000, score: 9, e: 0.31\n",
      "episode: 128/1000, score: 12, e: 0.3\n",
      "episode: 129/1000, score: 11, e: 0.3\n",
      "episode: 130/1000, score: 9, e: 0.3\n",
      "episode: 131/1000, score: 10, e: 0.29\n",
      "episode: 132/1000, score: 9, e: 0.29\n",
      "episode: 133/1000, score: 10, e: 0.29\n",
      "episode: 134/1000, score: 12, e: 0.29\n",
      "episode: 135/1000, score: 11, e: 0.28\n",
      "episode: 136/1000, score: 9, e: 0.28\n",
      "episode: 137/1000, score: 8, e: 0.28\n",
      "episode: 138/1000, score: 11, e: 0.27\n",
      "episode: 139/1000, score: 8, e: 0.27\n",
      "episode: 140/1000, score: 12, e: 0.27\n",
      "episode: 141/1000, score: 10, e: 0.27\n",
      "episode: 142/1000, score: 10, e: 0.26\n",
      "episode: 143/1000, score: 15, e: 0.26\n",
      "episode: 144/1000, score: 16, e: 0.26\n",
      "episode: 145/1000, score: 10, e: 0.25\n",
      "episode: 146/1000, score: 9, e: 0.25\n",
      "episode: 147/1000, score: 15, e: 0.25\n",
      "episode: 148/1000, score: 8, e: 0.24\n",
      "episode: 149/1000, score: 9, e: 0.24\n",
      "episode: 150/1000, score: 11, e: 0.24\n",
      "Episode:   150, average reward: 10.6, current epsilon: 0.24\n",
      "episode: 151/1000, score: 10, e: 0.24\n",
      "episode: 152/1000, score: 10, e: 0.24\n",
      "episode: 153/1000, score: 11, e: 0.23\n",
      "episode: 154/1000, score: 10, e: 0.23\n",
      "episode: 155/1000, score: 10, e: 0.23\n",
      "episode: 156/1000, score: 10, e: 0.23\n",
      "episode: 157/1000, score: 10, e: 0.22\n",
      "episode: 158/1000, score: 13, e: 0.22\n",
      "episode: 159/1000, score: 11, e: 0.22\n",
      "episode: 160/1000, score: 14, e: 0.22\n",
      "episode: 161/1000, score: 9, e: 0.21\n",
      "episode: 162/1000, score: 11, e: 0.21\n",
      "episode: 163/1000, score: 10, e: 0.21\n",
      "episode: 164/1000, score: 10, e: 0.21\n",
      "episode: 165/1000, score: 8, e: 0.21\n",
      "episode: 166/1000, score: 10, e: 0.2\n",
      "episode: 167/1000, score: 12, e: 0.2\n",
      "episode: 168/1000, score: 10, e: 0.2\n",
      "episode: 169/1000, score: 10, e: 0.2\n",
      "episode: 170/1000, score: 13, e: 0.19\n",
      "episode: 171/1000, score: 26, e: 0.19\n",
      "episode: 172/1000, score: 63, e: 0.18\n",
      "episode: 173/1000, score: 126, e: 0.16\n",
      "episode: 174/1000, score: 86, e: 0.14\n",
      "episode: 175/1000, score: 93, e: 0.13\n",
      "Episode:   175, average reward: 24.2, current epsilon: 0.13\n",
      "episode: 176/1000, score: 140, e: 0.11\n",
      "episode: 177/1000, score: 159, e: 0.097\n",
      "episode: 178/1000, score: 117, e: 0.086\n",
      "episode: 179/1000, score: 66, e: 0.081\n",
      "episode: 180/1000, score: 84, e: 0.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 181/1000, score: 113, e: 0.066\n",
      "episode: 182/1000, score: 148, e: 0.057\n",
      "episode: 183/1000, score: 181, e: 0.048\n",
      "episode: 184/1000, score: 62, e: 0.045\n",
      "episode: 185/1000, score: 130, e: 0.039\n",
      "episode: 186/1000, score: 157, e: 0.034\n",
      "episode: 187/1000, score: 105, e: 0.03\n",
      "episode: 188/1000, score: 187, e: 0.025\n",
      "episode: 189/1000, score: 99, e: 0.023\n",
      "episode: 190/1000, score: 166, e: 0.019\n",
      "episode: 191/1000, score: 131, e: 0.017\n",
      "episode: 192/1000, score: 181, e: 0.014\n",
      "episode: 193/1000, score: 183, e: 0.012\n",
      "episode: 194/1000, score: 165, e: 0.01\n",
      "episode: 195/1000, score: 184, e: 0.0083\n",
      "episode: 196/1000, score: 184, e: 0.0069\n",
      "episode: 197/1000, score: 153, e: 0.0059\n",
      "episode: 198/1000, score: 165, e: 0.005\n",
      "episode: 199/1000, score: 150, e: 0.0043\n",
      "episode: 200/1000, score: 173, e: 0.0036\n",
      "Episode:   200, average reward: 143.3, current epsilon: 0.00\n",
      "episode: 201/1000, score: 167, e: 0.0031\n",
      "episode: 202/1000, score: 142, e: 0.0027\n",
      "episode: 203/1000, score: 173, e: 0.0022\n",
      "episode: 204/1000, score: 158, e: 0.0019\n",
      "episode: 205/1000, score: 166, e: 0.0016\n",
      "episode: 206/1000, score: 172, e: 0.0014\n",
      "episode: 207/1000, score: 148, e: 0.0012\n",
      "episode: 208/1000, score: 84, e: 0.0011\n",
      "episode: 209/1000, score: 191, e: 0.001\n",
      "episode: 210/1000, score: 160, e: 0.001\n",
      "episode: 211/1000, score: 200, e: 0.001\n",
      "Saving trained model as cartpole-dqn.h5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = DQNAgent()\n",
    "agent.run()\n",
    "agent.performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11297ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1/100, score: 145\n",
      "episode: 2/100, score: 156\n",
      "episode: 3/100, score: 147\n",
      "episode: 4/100, score: 141\n",
      "episode: 5/100, score: 151\n",
      "episode: 6/100, score: 156\n",
      "episode: 7/100, score: 145\n",
      "episode: 8/100, score: 146\n",
      "episode: 9/100, score: 144\n",
      "episode: 10/100, score: 147\n",
      "episode: 11/100, score: 151\n",
      "episode: 12/100, score: 152\n",
      "episode: 13/100, score: 148\n",
      "episode: 14/100, score: 148\n",
      "episode: 15/100, score: 142\n",
      "episode: 16/100, score: 146\n",
      "episode: 17/100, score: 142\n",
      "episode: 18/100, score: 144\n",
      "episode: 19/100, score: 137\n",
      "episode: 20/100, score: 144\n",
      "episode: 21/100, score: 142\n",
      "episode: 22/100, score: 147\n",
      "episode: 23/100, score: 151\n",
      "episode: 24/100, score: 143\n",
      "episode: 25/100, score: 144\n",
      "episode: 26/100, score: 142\n",
      "episode: 27/100, score: 139\n",
      "episode: 28/100, score: 152\n",
      "episode: 29/100, score: 153\n",
      "episode: 30/100, score: 144\n",
      "episode: 31/100, score: 140\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0917ea8acd5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-76f3dcce07ee>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[1;31m#self.env.render()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m                 \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1567\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1569\u001b[1;33m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[0;32m   1570\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1571\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1105\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \"\"\"\n\u001b[0;32m   1694\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   4039\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4040\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4041\u001b[1;33m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   4042\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4043\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3369\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3370\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3371\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2936\u001b[0m       \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m     \"\"\"\n\u001b[1;32m-> 2938\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   2939\u001b[0m         *args, **kwargs)\n\u001b[0;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3062\u001b[0m     ]\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3064\u001b[1;33m     graph_function = ConcreteFunction(\n\u001b[0m\u001b[0;32m   3065\u001b[0m         func_graph_module.func_graph_from_py_func(\n\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func_graph, attrs, shared_func_graph, function_spec)\u001b[0m\n\u001b[0;32m   1539\u001b[0m     \u001b[1;31m# These each get a reference to the FuncGraph deleter since they use the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m     \u001b[1;31m# FuncGraph directly.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1541\u001b[1;33m     self._delayed_rewrite_functions = _DelayedRewriteGradientFunctions(\n\u001b[0m\u001b[0;32m   1542\u001b[0m         func_graph, self._attrs, self._garbage_collector)\n\u001b[0;32m   1543\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_order_tape_functions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func_graph, attrs, func_graph_deleter)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m     self._inference_function = _EagerDefinedFunction(\n\u001b[0m\u001b[0;32m    605\u001b[0m         \u001b[0m_inference_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         self._func_graph.inputs, self._func_graph.outputs, attrs)\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PythonGPU\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, graph, inputs, outputs, attrs)\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m       \u001b[0moutput_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m     fn = pywrap_tf_session.TF_GraphToFunction_wrapper(\n\u001b[0m\u001b[0;32m    438\u001b[0m         \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24907d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
